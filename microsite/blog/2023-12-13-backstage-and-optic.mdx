# Validating test traffic with Optic

Hey everybody, I'm Aramis, the maintainer of Backstage's OpenAPI tooling project area. Today, I'm going to be talking about our use of [Optic's](https://github.com/opticdev/optic) `capture` command and why I think it's really cool. Most of you reading this probably haven't heard about the new project area, so let me do a quick introduction and then we'll dive into our use of Optic.
## What is the OpenAPI tooling project area?
The OpenAPI tooling project area's goal is to enable developers to leverage schema-first development best practices in their Backstage plugins. This includes typed express routers based on an OpenAPI spec, autogenerated clients from a spec, and validation between OpenAPI spec and runtime traffic. You can find more information and a roadmap in [this meta issue](https://github.com/backstage/backstage/issues/17482) and for more history on how this became a project area, see the discussion on [the original issue](https://github.com/backstage/backstage/issues/2566).
## What other tools exist in the project area?
As I mentioned above, thus far, we've delivered 
1. an autogenerated express router stub with typings ([#15667](https://github.com/backstage/backstage/pull/15667))
2. an autogenerated client with Backstage-specific tie-ins ([#17470](https://github.com/backstage/backstage/pull/17470))
3. runtime validation with `express-openapi-validator` ([#17875](https://github.com/backstage/backstage/pull/17875))
and a few others. Again, check out [the meta issue](https://github.com/backstage/backstage/issues/17482) for the full rundown.
## Why do we need test schema validation?
All of the above tools require that the schema is correct at runtime or generate-time. Issues in validity or content are caught because of type errors or because of runtime errors during manual testing. We wanted to find a way to leverage existing content about correct behavior of the application to test the application and the OpenAPI schema. That leads us to using unit tests to validate input and output values against an OpenAPI spec. This reduces the feedback loop to a test command that gives you immediate insight about behavior -- with the added bonus that you can immediately codify new behavior and see it reflected. Truthfully, I didn't know this was an option until I stumbled across Optic's `capture` command.

The idea behind it is genius and yet remarkably simple -- validating your OpenAPI schema against the unit tests you've written by using a reverse proxy for network traffic. The reverse proxy captures the traffic and proxies it to your backend, it also keeps track of that traffic and reports on any mismatches between the schema and the traffic after execution. In the case of Backstage, we are able to adjust our use of `supertest` to call this reverse proxy and get input/output data.

You can find the PR that added this command [here](https://github.com/backstage/backstage/pull/19955). In that PR, you can see a few of the issues that this command helped uncover,
- [lack of error return types](https://github.com/backstage/backstage/pull/19955/files#diff-0b3e4d2e58a312186c7fdd6bc6cdcd7afecf80db667eda61e8c7565216077551R1069-R1072)
- [incorrect `additionalProperties`](https://github.com/backstage/backstage/pull/19955/files#diff-0b3e4d2e58a312186c7fdd6bc6cdcd7afecf80db667eda61e8c7565216077551R187)

And the best part about this command is that it runs as a CI validation step, so it catches any cases where a user may add a new code path and test but forgets to update the spec.

## Generating a spec from test traffic
The other side of the `capture` command is the ability to capture test traffic and _write_ an OpenAPI spec or update an OpenAPI spec accordingly. You can do this through the `--update interactive` option on the command. Currently, this is highly experimental in our use of the command in Backstage, but I've been impressed by the results. 

You can find a spec that I generated with this flow [here](https://github.com/sennyeya/backstage/blob/dev-ops-openapi-spec/plugins/azure-devops-backend/src/schema/openapi.yaml). 

I expect this command to be extremely useful in onboarding existing plugins to an OpenAPI schema-first workflow. Along with bootstrapping a full OpenAPI spec, it also shows users where test cases or branches are missing, which is a strong driver for updating coverage and/or updating the spec. 

With our current tooling, that experience would look a little something like this. 
1. You generate the spec from test data.
2. You realize that only 75% of your code is covered with test cases.
3. Your router has type errors for the other 25% of uncovered code.
4. You either decide to update just your spec (bad) or update your test cases and your spec(good). 
5. Reviewers appreciate that you updated the test cases and the spec and the code gets merged.

## Closing remarks

All in all, I've been extremely pleased with the test validation provided by Optic and I look forward to adopting other Optic tools in the future, like their linting or breaking changes validation.